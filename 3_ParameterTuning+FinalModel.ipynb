{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model\n",
    "\n",
    "This notebook serves to perform a deeper analysis of the best model and fine-tune this model with parameters using Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore') # suppress warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "# Home-made modules\n",
    "from utils import *\n",
    "from preprocessing import *\n",
    "from feature_creation import *\n",
    "from feature_selection import  *\n",
    "from dim_reduction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dd.read_csv('https://gist.githubusercontent.com/catyselman/9353e4e480ddf2db44b44a79e14718b5/raw/ded23e586ca5db1b4a566b1e289acd12ebf69357/bikeshare_hourly.csv', blocksize=25e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['realtemp']=(data.temp*41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning pipeline at 2019-05-19 20:35:58.673010\n",
      "\n",
      "Performing preprocessing steps...\n",
      "\tDropping the registered variable since we won't have this info\n",
      "\tDropping the causual variable since we won't have this info\n",
      "\tDropping the date variable since this information isencoded in other variables\n",
      "\tConverting year to a boolean variable...\n",
      "\tConverting season to a categorical variable...\n",
      "\tConverting month to a categorical variable...\n",
      "\tConverting day of week to a categorical variable...\n",
      "\tConverting hour of day to a categorical variable...\n",
      "\tConverting holiday or not to a boolean variable...\n",
      "\tConverting holiday or not to a boolean variable...\n",
      "\tConverting weather situation to a categorical variable...\n",
      "Preprocessing completed at 2019-05-19 20:35:58.844027, performed 12 steps\n",
      "New Shape of data: 15\n",
      "\n",
      "Performing feature creation...\n",
      "Feature Creation completed at 2019-05-19 20:35:58.845180, performed 0 steps\n",
      "New Shape of data: 15\n",
      "\n",
      "Dummifying...\n",
      "New Shape of data: 61\n",
      "\n",
      "Index(['weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4',\n",
      "       'weekday_5', 'weekday_6', 'hr_0', 'hr_1', 'hr_2', 'hr_3', 'hr_4',\n",
      "       'hr_5', 'hr_6', 'hr_7', 'hr_8', 'hr_9', 'hr_10', 'hr_11', 'hr_12',\n",
      "       'hr_13', 'hr_14', 'hr_15', 'hr_16', 'hr_17', 'hr_18', 'hr_19', 'hr_20',\n",
      "       'hr_21', 'hr_22', 'hr_23', 'mnth_1', 'mnth_2', 'mnth_3', 'mnth_4',\n",
      "       'mnth_5', 'mnth_6', 'mnth_7', 'mnth_8', 'mnth_9', 'mnth_10', 'mnth_11',\n",
      "       'mnth_12', 'season_1', 'season_2', 'season_3', 'season_4',\n",
      "       'weathersit_1', 'weathersit_2', 'weathersit_3', 'weathersit_4',\n",
      "       'instant', 'yr', 'holiday', 'workingday', 'temp', 'atemp', 'hum',\n",
      "       'windspeed', 'cnt', 'realtemp'],\n",
      "      dtype='object')\n",
      "Performing dimensionality reduction...\n",
      "Dimensionality reduction completed at 2019-05-19 20:36:01.067277, performed 0 steps\n",
      "New Shape of data: 61\n",
      "\n",
      "Performing feature selection...\n",
      "\tPerforming recursive feature elimination based on a Random Forest...\n",
      "\t\tRemaining Features: ['weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'hr_0', 'hr_1', 'hr_2', 'hr_3', 'hr_4', 'hr_5', 'hr_6', 'hr_7', 'hr_8', 'hr_9', 'hr_10', 'hr_11', 'hr_12', 'hr_13', 'hr_14', 'hr_15', 'hr_16', 'hr_17', 'hr_18', 'hr_19', 'hr_20', 'hr_21', 'hr_22', 'hr_23', 'mnth_5', 'mnth_6', 'mnth_7', 'mnth_9', 'season_1', 'season_2', 'season_4', 'weathersit_1', 'weathersit_2', 'weathersit_3', 'instant', 'yr', 'holiday', 'workingday', 'temp', 'atemp', 'hum', 'windspeed', 'cnt']\n",
      "Feature Selection completed at 2019-05-19 20:36:26.390483, performed 1 steps\n",
      "New Shape of train: 50\n",
      "\n",
      "Scoring models....\n",
      "\tAverage result for best Linear Regression: -13838326742987.865 +/- 19570349360484.42578\n",
      "\tBest parameters for Linear Regression: {}\n",
      "\tAverage result for best Random Forest: 0.7721453096435779 +/- 0.05072\n",
      "\tBest parameters for Random Forest: {'max_features': None, 'min_samples_leaf': 1, 'n_estimators': 90, 'random_state': 20192602}\n",
      "\tAverage result for best Gradient Boosting: 0.7216150985537495 +/- 0.02695\n",
      "\tBest parameters for Gradient Boosting: {'learning_rate': 0.2, 'min_samples_leaf': 3, 'n_estimators': 80, 'random_state': 20192602}\n",
      "\n",
      "Best model: RandomForestRegressor with params {'max_features': None, 'min_samples_leaf': 1, 'n_estimators': 90, 'random_state': 20192602}\n",
      "Evaluating model on the holdout...\n",
      "Final R2: 0.8448683446726967\n",
      "\n",
      "Pipeline finished! Completed execution at 2019-05-19 20:44:03.063390. Returning model...\n"
     ]
    }
   ],
   "source": [
    "pp = [drop_registered, drop_casual, drop_date, year_as_bool,\\\n",
    "      season_as_category, month_as_category, weekday_as_category, \\\n",
    "      hour_as_category, holiday_as_bool, working_day_as_bool, weather_sit_as_category, categorize_columns,\n",
    "     ]\n",
    "\n",
    "fc = []\n",
    "\n",
    "fs = [rfe]\n",
    "\n",
    "lm = {\"name\": \"Linear Regression\",\n",
    "      \"model\": LinearRegression(),\n",
    "      \"params\": {}\n",
    "     }\n",
    "\n",
    "rfr = {\"name\": \"Random Forest\",\n",
    "       \"model\": RandomForestRegressor(),\n",
    "       \"params\": {\"random_state\": [SEED],\n",
    "                  \"n_estimators\": list(range(10, 150, 10)),\n",
    "                  \"max_features\": [None, 'auto', 5],\n",
    "                  \"min_samples_leaf\": [1, 3]\n",
    "                 }\n",
    "      }\n",
    "\n",
    "gbr = {\"name\": \"Gradient Boosting\",\n",
    "       \"model\": GradientBoostingRegressor(),\n",
    "       \"params\": {\"random_state\": [SEED],\n",
    "                  \"n_estimators\": [50, 80 ],\n",
    "                  \"learning_rate\": [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "                  \"min_samples_leaf\": [1, 3]\n",
    "                 }\\\n",
    "      }\n",
    "\n",
    "models = [lm, rfr, gbr]\n",
    "\n",
    "best_model = pipeline_casero(data, preprocessing=pp, creation=fc, selection = fs, models=models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model of RandomForestRegressor with score of 84.49% was found on holdout after fine-tuning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
